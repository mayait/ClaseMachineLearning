{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayait/ClaseMachineLearning/blob/main/Logistic_regression_model_and_ROC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNFWDTVapXYz"
      },
      "source": [
        "# Regresi√≥n Logistica y ROC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0INKWhS1R_dN"
      },
      "outputs": [],
      "source": [
        "# importar bibliotecas necesarias\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# importar modelo de regresi√≥n log√≠stica y funciones de evaluaci√≥n de modelos\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.cm as cm\n",
        "from sklearn import metrics\n",
        "\n",
        "# importar funciones de divisi√≥n de datos y mapa de colores personalizados\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib.colors import ListedColormap\n",
        "import seaborn as sns\n",
        "\n",
        "# establecer la resoluci√≥n de la figura de matplotlib\n",
        "plt.rcParams['figure.dpi'] = 90\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7fNjtwrt6cvY"
      },
      "source": [
        "## Regresi√≥n logistica \n",
        "\n",
        "La regresi√≥n log√≠stica es un modelo utilizado para predecir la probabilidad de que algo pertenezca a una de dos clases. Por ejemplo, imagina que queremos predecir si un rat√≥n ser√° obeso o no. Podemos usar la regresi√≥n log√≠stica para predecir la probabilidad de que un correo electr√≥nico sea spam. La regresi√≥n log√≠stica se basa en una funci√≥n matem√°tica llamada funci√≥n log√≠stica que toma un valor de entrada y produce un valor de salida en el rango de 0 a 1. La salida representa la probabilidad de que el rat√≥n sea gordo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FNXYD1-OglE"
      },
      "outputs": [],
      "source": [
        "# generamos datos aleatorios de ejemplo\n",
        "np.random.seed(0)\n",
        "n_samples = 100\n",
        "data = pd.DataFrame({'peso':    [2, 1, 3, 6, 5, 6, 7, 8,],\n",
        "                     'gordura': [0, 0, 0, 0, 1, 1, 1, 1,]})\n",
        "\n",
        "# fit the logistic regression model\n",
        "X = data[['peso']]\n",
        "y = data['gordura']\n",
        "\n",
        "# creamos un gr√°fico de dispersi√≥n\n",
        "plt.figure(figsize=(9, 5))\n",
        "plt.scatter(data.peso, data.gordura,)\n",
        "plt.xlabel('Peso')\n",
        "plt.ylabel('Gordura')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brdk4Q2nht0Z"
      },
      "outputs": [],
      "source": [
        "# Instanciar el modelo\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Ajustamos el modelo\n",
        "y_pred = model.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ih_J5vWOWZjW"
      },
      "outputs": [],
      "source": [
        "#@title Logreg\n",
        "# plot the logistic curve\n",
        "# create a figure with a larger size\n",
        "fig = plt.figure(figsize=(10, 6), dpi=300)\n",
        "X_line = np.linspace(0, 10, 1000)\n",
        "y_line = model.predict_proba(X_line.reshape(-1,1))[:, 1]\n",
        "plt.plot(X_line, y_line, color='blue', linewidth=1,linestyle=':', label='Logistic Regression Line')\n",
        "\n",
        "plt.scatter(data['peso'], data['gordura'])\n",
        "\n",
        "# plot the threshold line\n",
        "threshold = 0.5\n",
        "plt.axhline(y=threshold, color='red', linestyle='-', label='Threshold Line')\n",
        "\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('Peso')\n",
        "plt.ylabel('Gordura')\n",
        "plt.show()  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iORdpircUMbj"
      },
      "source": [
        "## Matriz de confusi√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2UZ9AL58-eY"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWh9c40TUSYq"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, labels = ['No', 'Si']):\n",
        "    \"\"\"\n",
        "    Grafica una matriz de confusi√≥n basada en las etiquetas verdaderas y predichas.\n",
        "    \"\"\"\n",
        "\n",
        "    # calculate the confusion matrix\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    \n",
        "\n",
        "    # calculate sensitivity and specificity\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "    precision = tp / (tp + fp)\n",
        "    fpr = fp / (fp + tn)\n",
        "\n",
        "    # define a custom colormap\n",
        "    cmap = plt.cm.get_cmap('Greens', 2)\n",
        "\n",
        "    # get the confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "  \n",
        "\n",
        "    # plot the confusion matrix with the custom colormap\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "    disp.plot(cmap=cmap)\n",
        "    \n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "\n",
        "    print('tn', tn,'fp', fp)\n",
        "    print('fn', fn,'tp', tp)\n",
        "\n",
        "    print('Sensitivity / Recall / TPR:', sensitivity)\n",
        "    print('Specificity / selectivity / TNR:', specificity)\n",
        "    print('Fallout / FPR:', precision)\n",
        "    print('Precision / Positive predicted value:', fpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-1sq81gqrme"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(y, y_pred, ['No obeso', 'Obeso'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sGvi2iNsaHRV"
      },
      "source": [
        "## Curva ROC (Receiver Operating Characteristic) \n",
        "Esta curva representa la relaci√≥n entre la tasa de verdaderos positivos (TPR) y la tasa de falsos positivos (FPR) a medida que se var√≠a el umbral de decisi√≥n del modelo. \n",
        "\n",
        "En otras palabras, la curva ROC muestra c√≥mo cambia la capacidad de un modelo para clasificar correctamente los casos positivos y negativos a medida que se mueve el umbral de decisi√≥n.\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/13/Roc_curve.svg\" alt=\"ROC\" width=\"500\" height=\"500\">\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgYsggQkymfA"
      },
      "outputs": [],
      "source": [
        "!wget -nv https://github.com/mayait/ClaseAnalisisDatos/raw/main/machine_learning/datasets/diabetes_clean.csv"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dIxsDfGxfD2w"
      },
      "source": [
        "## üå∂Ô∏èüå∂Ô∏èüå∂Ô∏è Ejercicio\n",
        "\n",
        "Utiliza el dataset de diabetes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXsbu6gveF4u"
      },
      "outputs": [],
      "source": [
        "diabetes_df = pd.read_csv('diabetes_clean.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mLOr0dsy3MW"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.drop(\"diabetes\", axis=1).values\n",
        "y = diabetes_df[\"diabetes\"].values\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Instantiate the model\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# Fit the model\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predecimos Y_PRED\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_probs = logreg.predict_proba(X_test)[:, 1]\n",
        "\n",
        "\n",
        "print(y_pred_probs[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkL4hCxCfwkH"
      },
      "source": [
        "Observa c√≥mo la probabilidad de un diagn√≥stico de diabetes para los primeros 10 individuos en el conjunto de pruebas var√≠a de 0,01 a 0,79. Ahora, grafiquemos la curva ROC para visualizar el rendimiento utilizando diferentes umbrales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7ktzr0_gj_D"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(y_test, y_pred, ['Sin diabetes', 'Con Diabetes'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaErWBIiSMo9"
      },
      "outputs": [],
      "source": [
        "# Import roc_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# Generate ROC curve values: fpr, tpr, thresholds\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "\n",
        "# Plot tpr against fpr\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Diabetes Prediction')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb2GUd--gTjW"
      },
      "source": [
        "## üå∂Ô∏è ¬øQu√© te dice la gr√°fica sobre el rendimiento del modelo?\n",
        "\n",
        "\n",
        "A. El modelo es casi tan bueno como adivinar aleatoriamente la clase de cada observaci√≥n.\n",
        "\n",
        "B. El modelo es mucho peor que adivinar aleatoriamente la clase de cada observaci√≥n.\n",
        "\n",
        "C. El modelo es mucho mejor que adivinar aleatoriamente la clase de cada observaci√≥n.\n",
        "\n",
        "D. No es posible concluir si el modelo funciona mejor o peor que adivinar aleatoriamente la clase de cada observaci√≥n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W51OjbDojE8I"
      },
      "source": [
        "# AUC / √Årea bajo la curva\n",
        "El AUC representa el √°rea bajo la curva ROC y, mide la capacidad del modelo para distinguir entre casos positivos y negativos.\n",
        "\n",
        "El AUC oscila entre 0 y 1\n",
        "\n",
        "- 1 indica un modelo perfecto que es capaz de clasificar correctamente todos los casos positivos y negativos\n",
        "- 0,5 indica un modelo que es tan bueno como adivinar al azar la clase de cada observaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiqgYXXIka9-"
      },
      "outputs": [],
      "source": [
        "# Import roc_auc_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, ['Sin diabetes', 'Con Diabetes'])\n",
        "\n",
        "# Calculate the classification report\n",
        "# print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate roc_auc_score\n",
        "auc = roc_auc_score(y_test, y_pred_probs)\n",
        "print('AUC Score: ',auc)\n",
        "print('Un area bajo ROC de {}% significa que este modelo es {}% mejor que adivinar con una ruleta'.format(round(auc*100, 0), round(auc*100-50, 0) ))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2h-QRDwk_0k"
      },
      "source": [
        "## üå∂Ô∏è Comparemos los resultados de el mismo ejercicio evaluado con KNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Asn0_5zdk0_m"
      },
      "outputs": [],
      "source": [
        "# Soluci√≥n\n",
        "# Importar matriz de confusi√≥n\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=6)\n",
        "\n",
        "# Ajustar el modelo a los datos de entrenamiento\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predecir las etiquetas de los datos de prueba: y_pred\n",
        "y_pred = knn.predict(X_test)\n",
        "# predict probabilities for test set\n",
        "y_pred_probs = knn.predict_proba(X_test)[:, 1]\n",
        "# Generar la matriz de confusi√≥n y el informe de clasificaci√≥n\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "# Import roc_auc_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "plot_confusion_matrix(y_test, y_pred, ['Sin diabetes', 'Con Diabetes'])\n",
        "\n",
        "# Calculate the classification report\n",
        "# print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Calculate roc_auc_score\n",
        "auc = roc_auc_score(y_test, y_pred_probs)\n",
        "print('AUC Score: ',auc)\n",
        "print('Un area bajo ROC de {}% significa que este modelo es {}% mejor que adivinar con una ruleta'.format(round(auc*100, 0), round(auc*100-50, 0) ))\n",
        "\n",
        "# Import roc_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# Generate ROC curve values: fpr, tpr, thresholds\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "\n",
        "# Plot tpr against fpr\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Diabetes Prediction')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTA89M06owea"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPtfpIVPdQapHzZ1aFQPlEI",
      "include_colab_link": true,
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
