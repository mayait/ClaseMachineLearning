{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayait/ClaseMachineLearning/blob/main/SupervisedLearning/Classification/LinearRegEjercicio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ORMB4S-ThUb"
      },
      "source": [
        "# Regresi√≥n lineal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX_PfnT9ThUb"
      },
      "source": [
        "## Objetivo\n",
        "\n",
        "*   Usar scikit-learn para implementar un modelo de Linear Regression\n",
        "*   Crear un modelo, entrenarlo, evaluarlo y utilizarlo\n",
        "*   Optimizar el modelo con regularizaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnb9c2LTThUb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pylab as pl\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gk-arZKfThUc"
      },
      "outputs": [],
      "source": [
        "# Datasets\n",
        "!wget -nv https://raw.githubusercontent.com/mayait/ClaseAnalisisDatos/main/machine_learning/datasets/advertising_and_sales_clean.csv\n",
        "!wget -nv https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%202/data/FuelConsumptionCo2.csv\n",
        "!wget -nv https://github.com/mayait/ClaseAnalisisDatos/raw/main/machine_learning/datasets/crime.xlsx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40Av1Ly3ThUc"
      },
      "source": [
        "# Consumo de combustible\n",
        "\n",
        "### `FuelConsumption.csv`:\n",
        "\n",
        "Fuel consumption dataset, **`FuelConsumption.csv`**, Contiene las calificaciones de consumo de combustible espec√≠ficas del modelo y las emisiones estimadas de di√≥xido de carbono para veh√≠culos ligeros nuevos para la venta al por menor en Canad√°. [Dataset source](http://open.canada.ca/data/en/dataset/98f1a129-f628-4ce4-b24d-6f16bf24dd64)\n",
        "\n",
        "*   **MODELYEAR** e.g. 2014\n",
        "*   **MAKE** e.g. Acura\n",
        "*   **MODEL** e.g. ILX\n",
        "*   **VEHICLE CLASS** e.g. SUV\n",
        "*   **ENGINE SIZE** e.g. 4.7\n",
        "*   **CYLINDERS** e.g 6\n",
        "*   **TRANSMISSION** e.g. A6\n",
        "*   **FUELTYPE** e.g. z\n",
        "*   **FUEL CONSUMPTION in CITY(L/100 km)** e.g. 9.9\n",
        "*   **FUEL CONSUMPTION in HWY (L/100 km)** e.g. 8.9\n",
        "*   **FUEL CONSUMPTION COMB (L/100 km)** e.g. 9.2\n",
        "*   **CO2 EMISSIONS (g/km)** e.g. 182   --> low --> 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVKZy7NAThUc"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"FuelConsumption.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üå∂Ô∏è üêï Realiza un an√°lisis EDA a FuelConsumption, resume los hallazgos\n",
        "\n",
        "- An√°lisis de correlaci√≥n: Evaluar la correlaci√≥n entre la variable dependiente y las variables independientes mediante una matriz de correlaci√≥n o un gr√°fico de dispersi√≥n.\n",
        "- An√°lisis de normalidad: Verificar si las variables siguen una distribuci√≥n normal utilizando histogramas.\n",
        "\n",
        "- An√°lisis de valores at√≠picos: Buscar valores extremos en las variables.\n",
        "\n",
        "- An√°lisis de datos faltantes: Evaluar si hay valores faltantes en los datos y determinar c√≥mo manejarlos."
      ],
      "metadata": {
        "id": "Tiy2x8H4Ey1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HNJyZDJmG1fy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üå∂Ô∏è üêï Selecciona las variables"
      ],
      "metadata": {
        "id": "7M6fYK9iHC_j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9sNbtX3ThUd"
      },
      "outputs": [],
      "source": [
        "# Vamos a utilizar solo las siguientes caracteristicas para este ejercicio\n",
        "# Para X ser√°n: 'ENGINESIZE','CYLINDERS','FUELCONSUMPTION_CITY','FUELCONSUMPTION_HWY','FUELCONSUMPTION_COMB'\n",
        "# Para Y ser√°: 'CO2EMISSIONS'\n",
        "# Divide la data en train y test con un 70% para train y 30% para test\n",
        "\n",
        "from sklearn.model_selection import train_test_split    \n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# üå∂Ô∏è üêï Seleccionamos las caracteristicas que vamos a utilizar\n",
        "X = df[üå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏è]\n",
        "\n",
        "# üå∂Ô∏è üêï Seleccionamos la variable a predecir\n",
        "Y = df[üå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏è]\n",
        "\n",
        "# üå∂Ô∏è üêï Divide la data en train y test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(üå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏è)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# M√©todo de m√≠nimos cuadrados"
      ],
      "metadata": {
        "id": "uTN4G6UAHSkW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLtjNFMdThUd"
      },
      "outputs": [],
      "source": [
        "# üå∂Ô∏è üêï Haz una funci√≥n que entrene un modelo re regresi√≥n lineal recibiendo X_train, X_test, Y_train, Y_test\n",
        "# üå∂Ô∏è üêï La funcion devuelve el error cuadr√°tico medio (MSE) y el coeficiente de determinaci√≥n (R2) para train y test\n",
        "# üå∂Ô∏è üêï Calcula si el modelo est√° sobreajustado, subajustado o tiene un buen ajuste\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "def entrenar_modelo_minimos_cuadrados(X_train, X_test, Y_train, Y_test):\n",
        "    # üå∂Ô∏è üêï Instanciamos el modelo\n",
        "    regr = üå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏è # ¬øQue modelo?\n",
        "    \n",
        "    # Entrenamos el modelo\n",
        "    regr.fit(X_train, Y_train)\n",
        "    \n",
        "    # Hacemos las predicciones\n",
        "    Y_pred_train = regr.predict(X_train)\n",
        "    Y_pred_test = regr.predict(X_test)\n",
        "    \n",
        "    # üå∂Ô∏è üêï Calculamos el MSE para train y test mean_squared_error(...)\n",
        "    mse_train = üå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏è\n",
        "    mse_test = üå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏è\n",
        "    \n",
        "    # üå∂Ô∏è üêï Calculamos el R2 r2_score\n",
        "    r2_train = üå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏è\n",
        "    r2_test = üå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏è\n",
        "\n",
        "    # Imprime los resultados\n",
        "    print(\"MSE train: %.2f\" % mse_train)\n",
        "    print(\"MSE test: %.2f\" % mse_test)\n",
        "    print(\"R2 train: %.2f\" % r2_train)\n",
        "    print(\"R2 test: %.2f\" % r2_test)\n",
        "\n",
        "    # calcula si el modelo est√° sobreajustado, subajustado o tiene un buen ajuste\n",
        "    if r2_train > r2_test:  \n",
        "        print(\"El modelo est√° üå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏è\")\n",
        "    elif r2_train < r2_test:\n",
        "        print(\"El modelo est√° üå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏è\")\n",
        "    else:\n",
        "        print(\"El modelo üå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏èüå∂Ô∏è\")\n",
        "        \n",
        "    return mse_train, mse_test, r2_train, r2_test\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "El resultado deberia ser as√≠:\n",
        "MSE train: 563.97\n",
        "MSE test: 502.45\n",
        "R2 train: 0.86\n",
        "R2 test: 0.88\n",
        "El modelo est√° subajustado\n",
        "(563.9675185805852, 502.4460931860747, 0.8590623862972946, 0.8754316437513163)\n",
        "\"\"\"\n",
        "\n",
        "entrenar_modelo_minimos_cuadrados(X_train, X_test, Y_train, Y_test)"
      ],
      "metadata": {
        "id": "PPq2Lki9Haih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPDWfbgtThUd"
      },
      "source": [
        "# Ridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wu0pZZ4lThUd"
      },
      "outputs": [],
      "source": [
        "# Importa ridge de sklearn.linear_model\n",
        "# Crea una funcion que ajuste un modelo de regresion ridge con diferentes valores de alpha\n",
        "# La funcion debe devolver el MSE y el R2 para train y test\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "def entrenar_modelo_ridge(X_train, X_test, Y_train, Y_test):\n",
        "\n",
        "    # alphas\n",
        "    alphas = [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
        "\n",
        "\n",
        "    # Crea una tabla vacia para almacenar los resultados de Alpha, MSE y R2 para train y test\n",
        "    df_ridge = pd.DataFrame(columns=['Alpha', 'MSE_train', 'MSE_test', 'R2_train', 'R2_test'])\n",
        "\n",
        "    # Itera sobre los diferentes valores de alpha\n",
        "    for alpha in alphas:\n",
        "        # Instanciamos el modelo\n",
        "        ridge = Ridge(alpha=alpha)\n",
        "    \n",
        "        # Entrenamos el modelo\n",
        "        ridge.fit(X_train, Y_train)\n",
        "    \n",
        "        # Hacemos las predicciones\n",
        "        Y_pred_train = ridge.predict(X_train)\n",
        "        Y_pred_test = ridge.predict(X_test)\n",
        "    \n",
        "        # Calculamos el MSE\n",
        "        mse_train = mean_squared_error(Y_train, Y_pred_train)\n",
        "        mse_test = mean_squared_error(Y_test, Y_pred_test)\n",
        "        \n",
        "        # Calculamos el R2\n",
        "        r2_train = r2_score(Y_train, Y_pred_train)\n",
        "        r2_test = r2_score(Y_test, Y_pred_test)\n",
        "\n",
        "        # Guarda los resultados en la tabla df_ridge con pandas.concat\n",
        "        df_ridge = pd.concat([df_ridge, pd.DataFrame([[alpha, mse_train, mse_test, r2_train, r2_test]], columns=['Alpha', 'MSE_train', 'MSE_test', 'R2_train', 'R2_test'])])\n",
        "\n",
        "    # Imprime la tabla df_ridge\n",
        "    print(df_ridge)\n",
        "\n",
        "\n",
        "    # ¬øQue valor de alpha tiene el mejor R2, imprime todos los valores para ese alpha?\n",
        "    print(df_ridge[df_ridge['R2_test'] == df_ridge['R2_test'].max()])\n",
        "        \n",
        "    return mse_train, mse_test, r2_train, r2_test\n",
        "entrenar_modelo_ridge(X_train, X_test, Y_train, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zkgat_i8ThUe"
      },
      "source": [
        "# Lasso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17YJeHmiThUe"
      },
      "outputs": [],
      "source": [
        "# Importa lasso de sklearn.linear_model\n",
        "# Crea una funcion que ajuste un modelo de regresion lasso con diferentes valores de alpha\n",
        "# La funcion debe devolver el MSE y el R2 para train y test\n",
        "\n",
        "\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "def entrenar_modelo_lasso(X_train, X_test, Y_train, Y_test):\n",
        "\n",
        "    # alphas\n",
        "    alphas = [0.1, 1.0, 2, 10.0, 100.0, 1000.0]\n",
        "\n",
        "\n",
        "    # Crea una tabla vacia para almacenar los resultados de Alpha, MSE y R2 para train y test\n",
        "    df_lasso = pd.DataFrame(columns=['Alpha', 'MSE_train', 'MSE_test', 'R2_train', 'R2_test'])\n",
        "\n",
        "    # Itera sobre los diferentes valores de alpha\n",
        "    for alpha in alphas:\n",
        "        # Instanciamos el modelo\n",
        "        lasso = Lasso(alpha=alpha, max_iter = 10000)\n",
        "    \n",
        "        # Entrenamos el modelo\n",
        "        lasso.fit(X_train, Y_train)\n",
        "    \n",
        "        # Hacemos las predicciones\n",
        "        Y_pred_train = lasso.predict(X_train)\n",
        "        Y_pred_test = lasso.predict(X_test)\n",
        "    \n",
        "        # Calculamos el MSE\n",
        "        mse_train = mean_squared_error(Y_train, Y_pred_train)\n",
        "        mse_test = mean_squared_error(Y_test, Y_pred_test)\n",
        "        \n",
        "        # Calculamos el R2\n",
        "        r2_train = r2_score(Y_train, Y_pred_train)\n",
        "        r2_test = r2_score(Y_test, Y_pred_test)\n",
        "        \n",
        "\n",
        "        # Guarda los resultados en la tabla df_ridge con pandas.concat\n",
        "        df_lasso = pd.concat([df_lasso, pd.DataFrame([[alpha, mse_train, mse_test, r2_train, r2_test]], columns=['Alpha', 'MSE_train', 'MSE_test', 'R2_train', 'R2_test'])])\n",
        "\n",
        "    # Imprime la tabla df_ridge\n",
        "    print(df_lasso)\n",
        "\n",
        "\n",
        "    # ¬øQue valor de alpha tiene el mejor R2, imprime todos los valores para ese alpha?\n",
        "    print('El mejor valor de alpha es: ')\n",
        "    print(df_lasso[df_lasso['R2_test'] == df_lasso['R2_test'].max()])\n",
        "        \n",
        "    return mse_train, mse_test, r2_train, r2_test\n",
        "entrenar_modelo_lasso(X_train, X_test, Y_train, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta10_Jh7ThUe"
      },
      "source": [
        "# Polynomial"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Ajuste Polin√≥mico en Regresi√≥n Lineal\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Generar puntos de datos\n",
        "x = np.linspace(1, 7, num=20)\n",
        "y = x ** 2 + np.random.normal(scale=2, size=20)\n",
        "\n",
        "# Crear una figura con dos subplots\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 9))\n",
        "\n",
        "# Graficar el primer gr√°fico (regresi√≥n lineal sin ajuste)\n",
        "ax1.scatter(x, y, color='blue')\n",
        "ax1.set_title('Regresi√≥n Lineal Sin Ajuste')\n",
        "ax1.set_xlabel('X')\n",
        "ax1.set_ylabel('Y')\n",
        "\n",
        "# Ajustar una funci√≥n lineal (grado=1) sin ajuste\n",
        "pendiente, intercep = np.polyfit(x, y, 1)\n",
        "funcion_lineal = np.poly1d((pendiente, intercep))\n",
        "x_vals = np.linspace(x[0], x[-1], 100)\n",
        "y_vals = funcion_lineal(x_vals)\n",
        "ax1.plot(x_vals, y_vals, color='red')\n",
        "\n",
        "# Calcular RMSE y R^2\n",
        "y_pred = funcion_lineal(x)\n",
        "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
        "r2 = r2_score(y, y_pred)\n",
        "ax1.text(0.05, 0.9, 'RMSE: {:.2f}\\nR$^2$: {:.2f}'.format(rmse, r2),\n",
        "         transform=ax1.transAxes, bbox=dict(facecolor='white', edgecolor='black', pad=10))\n",
        "\n",
        "# Graficar el segundo gr√°fico (regresi√≥n lineal con ajuste polin√≥mico)\n",
        "ax2.scatter(x, y, color='blue')\n",
        "ax2.set_title('Regresi√≥n Lineal con Ajuste Polin√≥mico')\n",
        "ax2.set_xlabel('X')\n",
        "ax2.set_ylabel('Y')\n",
        "\n",
        "# Ajustar una funci√≥n polin√≥mica (grado=2) con ajuste\n",
        "grado = 2\n",
        "coeficientes = np.polyfit(x, y, grado)\n",
        "polinomio = np.poly1d(coeficientes)\n",
        "x_vals = np.linspace(x[0], x[-1], 100)\n",
        "y_vals = polinomio(x_vals)\n",
        "ax2.plot(x_vals, y_vals, color='green')\n",
        "\n",
        "# Calcular RMSE y R^2\n",
        "y_pred = polinomio(x)\n",
        "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
        "r2 = r2_score(y, y_pred)\n",
        "ax2.text(0.05, 0.9, 'RMSE: {:.2f}\\nR$^2$: {:.2f}'.format(rmse, r2),\n",
        "         transform=ax2.transAxes, bbox=dict(facecolor='white', edgecolor='black', pad=10))\n",
        "\n",
        "# Agregar un t√≠tulo a la figura\n",
        "fig.suptitle('Ajuste Polin√≥mico en Regresi√≥n Lineal', fontsize=24)\n",
        "\n",
        "# Ajustar el dise√±o y mostrar la figura\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RArEo2o1QjCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ds7y9Lp_ThUe"
      },
      "outputs": [],
      "source": [
        "# Crea una funci√≥n que ajuste un modelo de regresi√≥n polinomial con diferentes grados\n",
        "# Importa PolynomialFeatures    \n",
        "# Crea objeto PolynomialFeatures con el grado deseado\n",
        "# La funcion debe devolver el MSE y el R2 para train y test\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "def entrenar_modelo_polinomial(X_train, X_test, Y_train, Y_test):\n",
        "    \n",
        "        # grados\n",
        "        grados = [2, 3]\n",
        "    \n",
        "        # Crea una tabla vacia para almacenar los resultados de grado, MSE y R2 para train y test\n",
        "        df_polinomial = pd.DataFrame(columns=['Grado', 'MSE_train', 'MSE_test', 'R2_train', 'R2_test', 'Modelo'])\n",
        "    \n",
        "        # Itera sobre los diferentes grados\n",
        "        for grado in grados:\n",
        "            \n",
        "            # Instanciamos el objeto transformador PolynomialFeatures\n",
        "            poly = PolynomialFeatures(degree=grado)\n",
        "            \n",
        "            # Transforma los datos de entrenamiento y prueba en un conjunto de caracter√≠sticas polin√≥micas\n",
        "            X_train_poly = poly.fit_transform(X_train)\n",
        "            X_test_poly = poly.transform(X_test)\n",
        "\n",
        "            print('Grado: ', grado)\n",
        "            \n",
        "             # Entrenamos el modelo con Least Squares\n",
        "            print('Entrenando modelo con Least Squares')\n",
        "            mse_train, mse_test, r2_train, r2_test = entrenar_modelo(X_train_poly, X_test_poly, Y_train, Y_test)\n",
        "\n",
        "            # A√±adimos los resultados a la tabla df_polinomial\n",
        "            df_polinomial = pd.concat([df_polinomial, pd.DataFrame([[grado, mse_train, mse_test, r2_train, r2_test, 'Least Squares']], columns=['Grado', 'MSE_train', 'MSE_test', 'R2_train', 'R2_test', 'Modelo'])])\n",
        "\n",
        "            # Entrenamos el modelo con Ridge\n",
        "            print('Entrenando modelo con Ridge')\n",
        "            entrenar_modelo_ridge(X_train_poly, X_test_poly, Y_train, Y_test)\n",
        "\n",
        "            # Entrenamos el modelo con Lasso\n",
        "            print('Entrenando modelo con Lasso')\n",
        "            entrenar_modelo_lasso(X_train_poly, X_test_poly, Y_train, Y_test)\n",
        "            \n",
        "        return None\n",
        "\n",
        "entrenar_modelo_polinomial(X_train, X_test, Y_train, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalizaci√≥n Min-Max"
      ],
      "metadata": {
        "id": "hxItYtXaSy3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Min Max Norm\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Generar puntos de datos\n",
        "x = np.linspace(-30, 500, num=100)\n",
        "y = 2 * x + np.random.normal(scale=10, size=100)\n",
        "\n",
        "# Normalizar los datos utilizando la normalizaci√≥n min-max\n",
        "scaler = MinMaxScaler()\n",
        "x_norm = scaler.fit_transform(x.reshape(-1, 1)).ravel()\n",
        "y_norm = y.reshape(-1, 1).ravel()\n",
        "\n",
        "# Crear una figura con dos subplots\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 9))\n",
        "\n",
        "# Graficar el primer gr√°fico (datos originales)\n",
        "ax1.scatter(x, y, color='blue')\n",
        "ax1.set_title('Datos Originales')\n",
        "ax1.set_xlabel('X')\n",
        "ax1.set_ylabel('Y')\n",
        "\n",
        "# Graficar el segundo gr√°fico (datos normalizados)\n",
        "ax2.scatter(x_norm, y_norm, color='red')\n",
        "ax2.set_title('Datos Normalizados')\n",
        "ax2.set_xlabel('X (Normalizado)')\n",
        "ax2.set_ylabel('Y (Normalizado)')\n",
        "\n",
        "# Agregar un t√≠tulo a la figura\n",
        "fig.suptitle('Normalizaci√≥n Min-Max', fontsize=24)\n",
        "\n",
        "# Ajustar el dise√±o y mostrar la figura\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qkf0HpbQS3B0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alVbL84WThUe"
      },
      "outputs": [],
      "source": [
        "# Crea una funci√≥n que normalice los datos de train y test utilizando MinMaxScaler\n",
        "# Importa MinMaxScaler de sklearn.preprocessing\n",
        "# Crea objeto MinMaxScaler los datos de train y test\n",
        "# Ajustar el escalador a los datos de entrenamiento y transformar los datos\n",
        "# Crear un objeto LinearRegression y ajustar el modelo a los datos de entrenamiento escalados\n",
        "# Transformar los datos de prueba utilizando el mismo objeto escalador\n",
        "# Realizar predicciones sobre los datos de prueba escalados utilizando el modelo entrenado\n",
        "# Evaluar el rendimiento del modelo\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def entrenar_modelo_normalizado(X_train, X_test, Y_train, Y_test):\n",
        "    \n",
        "        # Instancia MinMaxScaler\n",
        "        scaler = MinMaxScaler()\n",
        "    \n",
        "        # Ajusta el escalador a los datos de entrenamiento\n",
        "        scaler.fit_transform(X_train)\n",
        "    \n",
        "        # Transforma los datos de entrenamiento\n",
        "        X_train_scaled = scaler.transform(X_train)\n",
        "    \n",
        "        # Transforma los datos de prueba\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # Entrenamos el modelo con Least Squares\n",
        "        print('Entrenando modelo con Least Squares')\n",
        "        entrenar_modelo(X_train_scaled, X_test_scaled, Y_train, Y_test)\n",
        "\n",
        "        # Entrenamos el modelo con Ridge\n",
        "        print('Entrenando modelo con Ridge')\n",
        "        entrenar_modelo_ridge(X_train_scaled, X_test_scaled, Y_train, Y_test)\n",
        "\n",
        "        # Entrenamos el modelo con Lasso\n",
        "        print('Entrenando modelo con Lasso')\n",
        "        entrenar_modelo_lasso(X_train_scaled, X_test_scaled, Y_train, Y_test)\n",
        "\n",
        "\n",
        "entrenar_modelo_normalizado(X_train, X_test, Y_train, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tam3W-ZvThUf"
      },
      "outputs": [],
      "source": [
        "# Importa ridge de sklearn.linear_model\n",
        "# Crea una funcion que ajuste un modelo de regresion ridge con diferentes valores de alpha\n",
        "# La funcion debe devolver el MSE y el R2 para train y test\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "def entrenar_modelo_ridge(X_train, X_test, Y_train, Y_test):\n",
        "\n",
        "    # alphas\n",
        "    alphas = [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
        "\n",
        "\n",
        "    # Crea una tabla vacia para almacenar los resultados de Alpha, MSE y R2 para train y test\n",
        "    df_ridge = pd.DataFrame(columns=['Alpha', 'MSE_train', 'MSE_test', 'R2_train', 'R2_test'])\n",
        "\n",
        "    # Itera sobre los diferentes valores de alpha\n",
        "    for alpha in alphas:\n",
        "        # Instanciamos el modelo\n",
        "        ridge = Ridge(alpha=alpha)\n",
        "    \n",
        "        # Entrenamos el modelo\n",
        "        ridge.fit(X_train, Y_train)\n",
        "    \n",
        "        # Hacemos las predicciones\n",
        "        Y_pred_train = ridge.predict(X_train)\n",
        "        Y_pred_test = ridge.predict(X_test)\n",
        "    \n",
        "        # Calculamos el MSE\n",
        "        mse_train = mean_squared_error(Y_train, Y_pred_train)\n",
        "        mse_test = mean_squared_error(Y_test, Y_pred_test)\n",
        "        \n",
        "        # Calculamos el R2\n",
        "        r2_train = r2_score(Y_train, Y_pred_train)\n",
        "        r2_test = r2_score(Y_test, Y_pred_test)\n",
        "\n",
        "        # Guarda los resultados en la tabla df_ridge con pandas.concat\n",
        "        df_ridge = pd.concat([df_ridge, pd.DataFrame([[alpha, mse_train, mse_test, r2_train, r2_test]], columns=['Alpha', 'MSE_train', 'MSE_test', 'R2_train', 'R2_test'])])\n",
        "\n",
        "    # Imprime la tabla df_ridge\n",
        "    print(df_ridge)\n",
        "\n",
        "\n",
        "    # ¬øQue valor de alpha tiene el mejor R2, imprime todos los valores para ese alpha?\n",
        "    print(df_ridge[df_ridge['R2_test'] == df_ridge['R2_test'].max()])\n",
        "        \n",
        "    return mse_train, mse_test, r2_train, r2_test\n",
        "entrenar_modelo_ridge(X_train, X_test, Y_train, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsUC0wZUThUf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "Crime"
      ],
      "metadata": {
        "id": "q92zm7kKDA8D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UCI Communities and Crime Unnormalized Data Set\n",
        "## Data Overview\n",
        "Context\n",
        "Introduction: The dataset used for this experiment is real and authentic. The dataset is acquired from UCI machine learning repository website. The title of the dataset is ‚ÄòCrime and Communities‚Äô. \n",
        "This dataset contains a total number of 147 attributes and 2216 instances.\n",
        "\n",
        "The per capita crimes variables were calculated using population values included in the 1995 FBI data (which differ from the 1990 Census values).\n",
        "\n",
        "Content\n",
        "\n",
        "The variables included in the dataset involve the community, such as the percent of the population considered urban, and the median family income, and involving law enforcement, such as per capita number of police officers, and percent of sworn full time police officers on patrol.\n",
        "\n",
        "The per capita violent crimes variable, **ViolentCrimesPerPop**, is the _target_ variable and is calculated using population and the sum of crime variables considered violent crimes in the United States: murder, rape, robbery, and assault.\n",
        "\n",
        "<ul>\n",
        "<li><strong>state</strong>:  US state (by number) - if considered, should be consided nominal (nominal)</li>\n",
        "<li><strong>county</strong>:  numeric code for county - many missing values (numeric)</li>\n",
        "<li><strong>communityname</strong>:  community name </li>\n",
        "<li><strong>population</strong>:  population for community (numeric - decimal)</li>\n",
        "<li><strong>householdsize</strong>:  mean people per household (numeric - decimal)</li>\n",
        "<li><strong>racepctblack</strong>:  percentage of population that is african american (numeric - decimal)</li>\n",
        "<li><strong>racePctWhite</strong>:  percentage of population that is caucasian (numeric - decimal)</li>\n",
        "<li><strong>racePctAsian</strong>:  percentage of population that is of asian heritage (numeric - decimal)</li>\n",
        "<li><strong>racePctHisp</strong>:  percentage of population that is of hispanic heritage (numeric - decimal)</li>\n",
        "<li><strong>agePct12t21</strong>:  percentage of population that is 12-21 in age (numeric - decimal)</li>\n",
        "<li><strong>agePct12t29</strong>:  percentage of population that is 12-29 in age (numeric - decimal)</li>\n",
        "<li><strong>agePct16t24</strong>:  percentage of population that is 16-24 in age (numeric - decimal)</li>\n",
        "<li><strong>agePct65up</strong>:  percentage of population that is 65 and over in age (numeric - decimal)</li>\n",
        "<li><strong>numbUrban</strong>:  number of people living in areas classified as urban (numeric - decimal)</li>\n",
        "<li><strong>pctUrban</strong>:  percentage of people living in areas classified as urban (numeric - decimal)</li>\n",
        "<li><strong>medIncome</strong>:  median household income (numeric - decimal)</li>\n",
        "<li><strong>pctWWage</strong>:  percentage of households with wage or salary income in 1989 (numeric - decimal)</li>\n",
        "<li><strong>pctWFarmSelf</strong>:  percentage of households with farm or self employment income in 1989 (numeric - decimal)</li>\n",
        "<li><strong>pctWInvInc</strong>:  percentage of households with investment / rent income in 1989 (numeric - decimal)</li>\n",
        "<li><strong>pctWSocSec</strong>:  percentage of households with social security income in 1989 (numeric - decimal)</li>\n",
        "<li><strong>pctWPubAsst</strong>:  percentage of households with public assistance income in 1989 (numeric - decimal)</li>\n",
        "<li><strong>pctWRetire</strong>:  percentage of households with retirement income in 1989 (numeric - decimal)</li>\n",
        "<li><strong>medFamInc</strong>:  median family income (differs from household income for non-family households) (numeric - decimal)</li>\n",
        "<li><strong>perCapInc</strong>:  per capita income (numeric - decimal)</li>\n",
        "<li><strong>whitePerCap</strong>:  per capita income for caucasians (numeric - decimal)</li>\n",
        "<li><strong>blackPerCap</strong>:  per capita income for african americans (numeric - decimal)</li>\n",
        "<li><strong>indianPerCap</strong>:  per capita income for native americans (numeric - decimal)</li>\n",
        "<li><strong>AsianPerCap</strong>:  per capita income for people with asian heritage (numeric - decimal)</li>\n",
        "<li><strong>OtherPerCap</strong>:  per capita income for people with 'other' heritage (numeric - decimal)</li>\n",
        "<li><strong>HispPerCap</strong>:  per capita income for people with hispanic heritage (numeric - decimal)</li>\n",
        "<li><strong>NumUnderPov</strong>:  number of people under the poverty level (numeric - decimal)</li>\n",
        "<li><strong>PctPopUnderPov</strong>:  percentage of people under the poverty level (numeric - decimal)</li>\n",
        "<li><strong>PctLess9thGrade</strong>:  percentage of people 25 and over with less than a 9th grade education (numeric - decimal)</li>\n",
        "<li><strong>PctNotHSGrad</strong>:  percentage of people 25 and over that are not high school graduates (numeric - decimal)</li>\n",
        "<li><strong>PctBSorMore</strong>:  percentage of people 25 and over with a bachelors degree or higher education (numeric - decimal)</li>\n",
        "<li><strong>PctUnemployed</strong>:  percentage of people 16 and over, in the labor force, and unemployed (numeric - decimal)</li>\n",
        "<li><strong>PctEmploy</strong>:  percentage of people 16 and over who are employed (numeric - decimal)</li>\n",
        "<li><strong>PctEmplManu</strong>:  percentage of people 16 and over who are employed in manufacturing (numeric - decimal)</li>\n",
        "<li><strong>PctEmplProfServ</strong>:  percentage of people 16 and over who are employed in professional services (numeric - decimal)</li>\n",
        "<li><strong>PctOccupManu</strong>:  percentage of people 16 and over who are employed in manufacturing (numeric - decimal) </li>\n",
        "<li><strong>PctOccupMgmtProf</strong>:  percentage of people 16 and over who are employed in management or professional occupations (numeric - decimal)</li>\n",
        "<li><strong>MalePctDivorce</strong>:  percentage of males who are divorced (numeric - decimal)</li>\n",
        "<li><strong>MalePctNevMarr</strong>:  percentage of males who have never married (numeric - decimal)</li>\n",
        "<li><strong>FemalePctDiv</strong>:  percentage of females who are divorced (numeric - decimal)</li>\n",
        "<li><strong>TotalPctDiv</strong>:  percentage of population who are divorced (numeric - decimal)</li>\n",
        "<li><strong>PersPerFam</strong>:  mean number of people per family (numeric - decimal)</li>\n",
        "<li><strong>PctFam2Par</strong>:  percentage of families (with kids) that are headed by two parents (numeric - decimal)</li>\n",
        "<li><strong>PctKids2Par</strong>:  percentage of kids in family housing with two parents (numeric - decimal)</li>\n",
        "<li><strong>PctYoungKids2Par</strong>:  percent of kids 4 and under in two parent households (numeric - decimal)</li>\n",
        "<li><strong>PctTeen2Par</strong>:  percent of kids age 12-17 in two parent households (numeric - decimal)</li>\n",
        "<li><strong>PctWorkMomYoungKids</strong>:  percentage of moms of kids 6 and under in labor force (numeric - decimal)</li>\n",
        "<li><strong>PctWorkMom</strong>:  percentage of moms of kids under 18 in labor force (numeric - decimal)</li>\n",
        "<li><strong>NumIlleg</strong>:  number of kids born to never married (numeric - decimal)</li>\n",
        "<li><strong>PctIlleg</strong>:  percentage of kids born to never married (numeric - decimal)</li>\n",
        "<li><strong>NumImmig</strong>:  total number of people known to be foreign born (numeric - decimal)</li>\n",
        "<li><strong>PctImmigRecent</strong>:  percentage of _immigrants_ who immigated within last 3 years (numeric - decimal)</li>\n",
        "<li><strong>PctImmigRec5</strong>:  percentage of _immigrants_ who immigated within last 5 years (numeric - decimal)</li>\n",
        "<li><strong>PctImmigRec8</strong>:  percentage of _immigrants_ who immigated within last 8 years (numeric - decimal)</li>\n",
        "<li><strong>PctImmigRec10</strong>:  percentage of _immigrants_ who immigated within last 10 years (numeric - decimal)</li>\n",
        "<li><strong>PctRecentImmig</strong>:  percent of _population_ who have immigrated within the last 3 years (numeric - decimal)</li>\n",
        "<li><strong>PctRecImmig5</strong>:  percent of _population_ who have immigrated within the last 5 years (numeric - decimal)</li>\n",
        "<li><strong>PctRecImmig8</strong>:  percent of _population_ who have immigrated within the last 8 years (numeric - decimal)</li>\n",
        "<li><strong>PctRecImmig10</strong>:  percent of _population_ who have immigrated within the last 10 years (numeric - decimal)</li>\n",
        "<li><strong>PctSpeakEnglOnly</strong>:  percent of people who speak only English (numeric - decimal)</li>\n",
        "<li><strong>PctNotSpeakEnglWell</strong>:  percent of people who do not speak English well (numeric - decimal)</li>\n",
        "<li><strong>PctLargHouseFam</strong>:  percent of family households that are large (6 or more) (numeric - decimal)</li>\n",
        "<li><strong>PctLargHouseOccup</strong>:  percent of all occupied households that are large (6 or more people) (numeric - decimal)</li>\n",
        "<li><strong>PersPerOccupHous</strong>:  mean persons per household (numeric - decimal)</li>\n",
        "<li><strong>PersPerOwnOccHous</strong>:  mean persons per owner occupied household (numeric - decimal)</li>\n",
        "<li><strong>PersPerRentOccHous</strong>:  mean persons per rental household (numeric - decimal)</li>\n",
        "<li><strong>PctPersOwnOccup</strong>:  percent of people in owner occupied households (numeric - decimal)</li>\n",
        "<li><strong>PctPersDenseHous</strong>:  percent of persons in dense housing (more than 1 person per room) (numeric - decimal)</li>\n",
        "<li><strong>PctHousLess3BR</strong>:  percent of housing units with less than 3 bedrooms (numeric - decimal)</li>\n",
        "<li><strong>MedNumBR</strong>:  median number of bedrooms (numeric - decimal)</li>\n",
        "<li><strong>HousVacant</strong>:  number of vacant households (numeric - decimal)</li>\n",
        "<li><strong>PctHousOccup</strong>:  percent of housing occupied (numeric - decimal)</li>\n",
        "<li><strong>PctHousOwnOcc</strong>:  percent of households owner occupied (numeric - decimal)</li>\n",
        "<li><strong>PctVacantBoarded</strong>:  percent of vacant housing that is boarded up (numeric - decimal)</li>\n",
        "<li><strong>PctVacMore6Mos</strong>:  percent of vacant housing that has been vacant more than 6 months (numeric - decimal)</li>\n",
        "<li><strong>MedYrHousBuilt</strong>:  median year housing units built (numeric - decimal)</li>\n",
        "<li><strong>PctHousNoPhone</strong>:  percent of occupied housing units without phone (in 1990, this was rare!) (numeric - decimal)</li>\n",
        "<li><strong>PctWOFullPlumb</strong>:  percent of housing without complete plumbing facilities (numeric - decimal)</li>\n",
        "<li><strong>OwnOccLowQuart</strong>:  owner occupied housing - lower quartile value (numeric - decimal)</li>\n",
        "<li><strong>OwnOccMedVal</strong>:  owner occupied housing - median value (numeric - decimal)</li>\n",
        "<li><strong>OwnOccHiQuart</strong>:  owner occupied housing - upper quartile value (numeric - decimal)</li>\n",
        "<li><strong>RentLowQ</strong>:  rental housing - lower quartile rent (numeric - decimal)</li>\n",
        "<li><strong>RentMedian</strong>:  rental housing - median rent (Census variable H32B from file STF1A) (numeric - decimal)</li>\n",
        "<li><strong>RentHighQ</strong>:  rental housing - upper quartile rent (numeric - decimal)</li>\n",
        "<li><strong>MedRent</strong>:  median gross rent (Census variable H43A from file STF3A - includes utilities) (numeric - decimal)</li>\n",
        "<li><strong>MedRentPctHousInc</strong>:  median gross rent as a percentage of household income (numeric - decimal)</li>\n",
        "<li><strong>MedOwnCostPctInc</strong>:  median owners cost as a percentage of household income - for owners with a mortgage (numeric - decimal)</li>\n",
        "<li><strong>MedOwnCostPctIncNoMtg</strong>:  median owners cost as a percentage of household income - for owners without a mortgage (numeric - decimal)</li>\n",
        "<li><strong>NumInShelters</strong>:  number of people in homeless shelters (numeric - decimal)</li>\n",
        "<li><strong>NumStreet</strong>:  number of homeless people counted in the street (numeric - decimal)</li>\n",
        "<li><strong>PctForeignBorn</strong>:  percent of people foreign born (numeric - decimal)</li>\n",
        "<li><strong>PctBornSameState</strong>:  percent of people born in the same state as currently living (numeric - decimal)</li>\n",
        "<li><strong>PctSameHouse85</strong>:  percent of people living in the same house as in 1985 (5 years before) (numeric - decimal)</li>\n",
        "<li><strong>PctSameCity85</strong>:  percent of people living in the same city as in 1985 (5 years before) (numeric - decimal)</li>\n",
        "<li><strong>PctSameState85</strong>:  percent of people living in the same state as in 1985 (5 years before) (numeric - decimal)</li>\n",
        "<li><strong>FTPolicePerPop</strong>:  sworn full time police officers per 100K population (numeric - decimal)</li>\n",
        "<li><strong>FTPoliceFieldPerPop</strong>:  sworn full time police officers in field operations (on the street as opposed to administrative etc) per 100K population (numeric - decimal)</li>\n",
        "<li><strong>RacialMatchCommPol</strong>:  a measure of the racial match between the community and the police force. High values indicate proportions in community and police force are similar (numeric - decimal)</li>\n",
        "<li><strong>PctPolicWhite</strong>:  percent of police that are caucasian (numeric - decimal)</li>\n",
        "<li><strong>PctPolicBlack</strong>:  percent of police that are african american (numeric - decimal)</li>\n",
        "<li><strong>PctPolicHisp</strong>:  percent of police that are hispanic (numeric - decimal)</li>\n",
        "<li><strong>PctPolicAsian</strong>:  percent of police that are asian (numeric - decimal)</li>\n",
        "<li><strong>PctPolicMinor</strong>:  percent of police that are minority of any kind (numeric - decimal)</li>\n",
        "<li><strong>OfficAssgnDrugUnits</strong>:  number of officers assigned to special drug units (numeric - decimal)</li>\n",
        "<li><strong>PolicAveOTWorked</strong>:  police average overtime worked (numeric - decimal)</li>\n",
        "<li><strong>LandArea</strong>:  land area in square miles (numeric - decimal)</li>\n",
        "<li><strong>PopDens</strong>:  population density in persons per square mile (numeric - decimal)</li>\n",
        "<li><strong>PctUsePubTrans</strong>:  percent of people using public transit for commuting (numeric - decimal)</li>\n",
        "<li><strong>PolicCars</strong>:  number of police cars (numeric - decimal)</li>\n",
        "<li><strong>PolicOperBudg</strong>:  police operating budget (numeric - decimal)</li>\n",
        "<li><strong>PctPolicOnPatr</strong>:  percent of sworn full time police officers on patrol (numeric - decimal)</li>\n",
        "<li><strong>GangUnitDeploy</strong>:  gang unit deployed (numeric - decimal - but really ordinal - 0 means NO, 1 means YES, 0.5 means Part Time)</li>\n",
        "<li><strong>PolicBudgPerPop</strong>:  police operating budget per population (numeric - decimal)</li>\n",
        "<li><strong>ViolentCrimesPerPop</strong>:  total number of violent crimes per 100K popuation (numeric - decimal) target variable to be predicted; not in the crimeTest.csv data.</li>\n",
        "</ul>"
      ],
      "metadata": {
        "id": "wD4Z2Q67BzrV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0N_ekfxVThUc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split    \n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# importa en df crime.xlsx\n",
        "df = pd.read_excel(\"crime.xlsx\")\n",
        "df.sample(10)\n",
        "\n",
        "# Seleccionamos las caracteristicas que vamos a utilizar que son todas menos ViolentCrimesPerPop\n",
        "X = df.drop(['ViolentCrimesPerPop'], axis=1)\n",
        "\n",
        "# Seleccionamos la variable a predecir\n",
        "Y = df['ViolentCrimesPerPop']\n",
        "\n",
        "# Divide la data en train y test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Instanciamos el modelo\n",
        "regr = LinearRegression()\n",
        "\n",
        "# Entrenamos el modelo\n",
        "regr.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ad2R86FEThUf"
      },
      "outputs": [],
      "source": [
        "df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNryZO5pThUf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OU5U1MGThUf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7j5t2ZhtThUf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}