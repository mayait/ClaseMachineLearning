{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgDk7K5M1qTS"
      },
      "outputs": [],
      "source": [
        "!pip install easyocr -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9tlccTk1s-c"
      },
      "outputs": [],
      "source": [
        "import easyocr\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmLA33EA3IfQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Obtén el nombre del archivo cargado (asumiendo que solo se cargó un archivo)\n",
        "imagen = list(uploaded.keys())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k314uzJu1vj5"
      },
      "outputs": [],
      "source": [
        "# Reemplaza 'nombre_imagen.jpg' con el nombre de tu archivo de imagen\n",
        "imagen = cv2.imread('cedula.png')\n",
        "cv2_imshow(imagen)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l4P92DO2B_K"
      },
      "outputs": [],
      "source": [
        "# Puedes aplicar técnicas de preprocesamiento aquí si es necesario\n",
        "# Por ejemplo, convertir a escala de grises, corrección de perspectiva, etc.\n",
        "# En este ejemplo, simplemente redimensionamos la imagen\n",
        "scale_percent = 50 # porcentaje de la escala original\n",
        "width = int(imagen.shape[1] * scale_percent / 100)\n",
        "height = int(imagen.shape[0] * scale_percent / 100)\n",
        "dim = (width, height)\n",
        "imagen_resized = cv2.resize(imagen, dim, interpolation=cv2.INTER_AREA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UTzTnRK2F0Q"
      },
      "outputs": [],
      "source": [
        "lector = easyocr.Reader(['es'], gpu=True) # Reemplaza 'en' con el código de idioma de la identificación si es necesario\n",
        "\n",
        "resultado = lector.readtext(imagen_resized)\n",
        "\n",
        "# Imprimir y mostrar el resultado\n",
        "clear_output()\n",
        "cv2_imshow(imagen_resized)\n",
        "for i, r in enumerate(resultado):\n",
        "    print(f\"Texto {i + 1}: {r[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVp44pUi31XS"
      },
      "outputs": [],
      "source": [
        "imagen_con_bloques = imagen_resized.copy()\n",
        "\n",
        "for i, r in enumerate(resultado):\n",
        "    (x1, y1), (x2, y2), (x3, y3), (x4, y4) = r[0]\n",
        "    cv2.rectangle(imagen_con_bloques, (int(x1), int(y1)), (int(x3), int(y3)), (0, 255, 0), 2)\n",
        "    \n",
        "    bloque_numero = f\"{i + 1}\"\n",
        "    cv2.putText(imagen_con_bloques, bloque_numero, (int(x1), int(y1 - 5)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "cv2_imshow(imagen_con_bloques)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRVvJi-G9J5g"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Carga la imagen del DNI\n",
        "img = cv2.imread('cedula.png')\n",
        "\n",
        "# Convierte la imagen a escala de grises\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Aplica umbralización adaptativa\n",
        "thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
        "\n",
        "# Aplica dilatación y erosión para eliminar el ruido y conectar regiones\n",
        "kernel = np.ones((3, 3), np.uint8)\n",
        "thresh = cv2.dilate(thresh, kernel, iterations=1)\n",
        "thresh = cv2.erode(thresh, kernel, iterations=1)\n",
        "\n",
        "# Encuentra los contornos en la imagen y selecciona el más grande\n",
        "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "contour_sizes = [(cv2.contourArea(contour), contour) for contour in contours]\n",
        "biggest_contour = max(contour_sizes, key=lambda x: x[0])[1]\n",
        "\n",
        "# Calcula los puntos de la imagen para aplicar la transformación de perspectiva\n",
        "rect = cv2.minAreaRect(biggest_contour)\n",
        "box = cv2.boxPoints(rect)\n",
        "box = np.int0(box)\n",
        "\n",
        "# Calcula la matriz de transformación y aplica la transformación a la imagen\n",
        "width, height = 600, 400\n",
        "src_pts = box.astype(\"float32\")\n",
        "dst_pts = np.array([[0, height-1], [0, 0], [width-1, 0], [width-1, height-1]], dtype=\"float32\")\n",
        "M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
        "dst = cv2.warpPerspective(img, M, (width, height))\n",
        "\n",
        "# Muestra la imagen original y la imagen transformada\n",
        "cv2_imshow(img)\n",
        "cv2_imshow(dst)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueyswALE9Lur"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y tesseract-ocr\n",
        "!apt-get install -y libtesseract-dev"
      ],
      "metadata": {
        "id": "KGf6sdT6C2PW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n"
      ],
      "metadata": {
        "id": "4i-AO8BTC2jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "from pytesseract import Output\n"
      ],
      "metadata": {
        "id": "GbcU4rMRC3cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply adaptive thresholding\n",
        "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "\n",
        "    return thresh\n"
      ],
      "metadata": {
        "id": "34McTQN3C4fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_info(image, field_coords):\n",
        "    # Apply OCR on the image\n",
        "    data = pytesseract.image_to_data(image, output_type=Output.DICT)\n",
        "\n",
        "    extracted_info = {}\n",
        "\n",
        "    for name, coords in field_coords.items():\n",
        "        x, y, w, h = coords\n",
        "        field_text = ''\n",
        "\n",
        "        for i in range(len(data['text'])):\n",
        "            if (\n",
        "                data['left'][i] >= x and data['top'][i] >= y\n",
        "                and data['left'][i] + data['width'][i] <= x + w\n",
        "                and data['top'][i] + data['height'][i] <= y + h\n",
        "            ):\n",
        "                field_text += data['text'][i] + ' '\n",
        "\n",
        "        extracted_info[name] = field_text.strip()\n",
        "\n",
        "    return extracted_info\n"
      ],
      "metadata": {
        "id": "7qbOk9qrC50H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define field coordinates (replace these with the correct coordinates for your ID cards)\n",
        "field_coords = {\n",
        "    'Name': (50, 50, 200, 40),\n",
        "    'ID Number': (50, 100, 200, 40),\n",
        "    'Date of Birth': (50, 150, 200, 40)\n",
        "}\n",
        "\n",
        "# Process each ID card image (replace 'id_card_1.jpg', 'id_card_2.jpg' with your file names)\n",
        "for image_path in ['cedula.png']:\n",
        "    preprocessed_image = preprocess_image(image_path)\n",
        "    extracted_info = extract_info(preprocessed_image, field_coords)\n",
        "\n",
        "    print(f\"Information extracted from {image_path}:\")\n",
        "    for field, value in extracted_info.items():\n",
        "        print(f\"{field}: {value}\")\n",
        "\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "psQPzWftC9hB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}